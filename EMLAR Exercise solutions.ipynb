{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    \"\"\" read corpus from '\\n'-delimited text file\n",
    "    returns a list of syllables \"\"\"\n",
    "\n",
    "    # initialize the return list as an empty list\n",
    "    result = []\n",
    "\n",
    "    # open the file for reading and loop over the lines\n",
    "    for line in open(filename, 'r'):\n",
    "        # get rid of end-of-line ('\\n') symbols \n",
    "        syll = line.strip()\n",
    "        # put syllable at end of list\n",
    "        result.append(syll)\n",
    "\n",
    "    # now that the result list is filled up, return it\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_corpus(list_of_syllables):\n",
    "    \"\"\" extract count of uni- & bigram occurrences from sequence\n",
    "    of syllables in list_of_syllables \"\"\"\n",
    "\n",
    "    # dictionaries to hold the counts of the unigrams & bigrams\n",
    "    unigram_dict = {}\n",
    "    bigram_dict = {}\n",
    "\n",
    "    # loop over the indices of list_of_syllables until the first to last element\n",
    "    for syll_idx in range(len(list_of_syllables) - 1):\n",
    "        # form unigram of syllables at index\n",
    "        unigram = (list_of_syllables[syll_idx])\n",
    "\n",
    "        # see if we have already seen this unigram\n",
    "        if unigram in unigram_dict:\n",
    "            # if so, up the count by 1\n",
    "            unigram_dict[unigram] += 1\n",
    "        else:\n",
    "            # if not, set the count to 1\n",
    "            unigram_dict[unigram] = 1\n",
    "\n",
    "        # form bigram of subsequent syllables\n",
    "        bigram = (list_of_syllables[syll_idx], list_of_syllables[syll_idx + 1])\n",
    "        # see if we have already seen this bigram\n",
    "        if bigram in bigram_dict:\n",
    "            # if so, up the count by 1\n",
    "            bigram_dict[bigram] += 1\n",
    "        else:\n",
    "            # if not, set the count to 1\n",
    "            bigram_dict[bigram] = 1\n",
    "\n",
    "    # correct for the off-by-1:\n",
    "    unigram = list_of_syllables[-1]\n",
    "    if unigram in unigram_dict:\n",
    "        unigram_dict[unigram] += 1\n",
    "    else:\n",
    "        unigram_dict[unigram] = 1\n",
    "\n",
    "    # return the dictionaries with the unigram and bigram counts\n",
    "    return unigram_dict, bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimated_bigram_probability(bigram, unigram_dict, bigram_dict):\n",
    "    \"\"\" estimate the probability of bigram (= (syll_1,syll_2)) by:\n",
    "    (count (syll_1,syll_2)) / (count syll_1)\n",
    "    \"\"\"\n",
    "\n",
    "    # set the count to zero\n",
    "    count = 0\n",
    "\n",
    "    # check if bigram is actually in our dict\n",
    "    if bigram in bigram_dict:\n",
    "        # if so, set count to the value from bigram_dict\n",
    "        count = bigram_dict[bigram]\n",
    "\n",
    "    # divide the (bigram) count by the unigram count of the first syllable\n",
    "    # to get the probability\n",
    "    prob = count / unigram_dict[bigram[0]]\n",
    "\n",
    "    # return the calculated probability\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimated_sequence_probability(list_of_syllables, unigram_dict, bigram_dict):\n",
    "    \"\"\" estimate probability of sequence of syllables,\n",
    "    represented as a list \"\"\"\n",
    "    \n",
    "    # set probability to 1 initially\n",
    "    prob = 1.\n",
    "\n",
    "    # loop over sequence indices\n",
    "    for syll_idx in range(len(list_of_syllables) - 1):\n",
    "        # form bigram from subsequent syllables\n",
    "        bigram = (list_of_syllables[syll_idx], list_of_syllables[syll_idx + 1])\n",
    "        \n",
    "        # multiply previous probability with probability of this bigram\n",
    "        prob = prob * estimated_bigram_probability(bigram, unigram_dict, bigram_dict)\n",
    "\n",
    "    # return the estimated probability of the entire sequence\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(unigram_dict, bigram_dict):\n",
    "    \"\"\" test the model on saffran's words and non-words\n",
    "    \"\"\"\n",
    "    \n",
    "    # the words and non-words from saffran\n",
    "    words = [['tu','pi','ro'],\n",
    "             ['go','la','bu'],\n",
    "             ['bi','da','ku'],\n",
    "             ['pa','do','ti']]\n",
    "    non_words = [['da','pi','ku'],\n",
    "                 ['ti','la','do']]\n",
    "\n",
    "    # calculate the sum of the probabilities of the words\n",
    "    sum_words = 0\n",
    "    for word in words:\n",
    "        sum_words += estimated_sequence_probability(word, unigram_dict, bigram_dict)\n",
    "\n",
    "    # divide by the number of words to get the average\n",
    "    average_word = sum_words / len(words)\n",
    "\n",
    "    # idem for the non-words\n",
    "    sum_non_words = 0\n",
    "    for non_word in non_words:\n",
    "        sum_non_words += estimated_sequence_probability(non_word, unigram_dict, bigram_dict)\n",
    "    # divide by the number of words to get the average        \n",
    "    average_non_word = sum_non_words / len(non_words)\n",
    "\n",
    "    print('Average probability for words:', average_word)\n",
    "    print('Average probability for non-words:', average_non_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    corpus = read_corpus(corfile)\n",
    "    unigram_dict, bigram_dict = process_corpus(corpus)\n",
    "    test_model(unigram_dict, bigram_dict)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
